{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение с использованием одного нейрона в Flux.jl\n",
    "\n",
    "В этой записной книжке мы будем использовать `Flux` для создания одного нейрона и обучим его, как мы это делали вручную в записной книжке 10!\n",
    "\n",
    "### Чтение данных и их обработка\n",
    "\n",
    "Давайте начнем с чтения в наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using TextParse\n",
    "using DataFrames\n",
    "\n",
    "apples = CSV.read(\"data/Apple_Golden_1.csv\")\n",
    "bananas = CSV.read(\"data/bananas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и обрабатаем их для извлечения информации о красной и зеленой окраске на наших изображениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = :red\n",
    "col2 = :green\n",
    "\n",
    "x_apples  = [ [apples[i, col1], apples[i, col2]] for i in 1:size(apples)[1] ]\n",
    "x_bananas = [ [bananas[i, col1], bananas[i, col2]] for i in 1:size(bananas)[1] ]\n",
    "\n",
    "xs = vcat(x_apples, x_bananas)\n",
    "\n",
    "ys = vcat( zeros(size(x_apples)[1]), ones(size(x_bananas)[1]) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входные данные находятся в `xs`, а метки (истинные классификации как бананы или яблоки) - в` ys`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование `Flux.jl`\n",
    "\n",
    "Теперь мы можем загрузить `Flux`, чтобы начать работу!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнем блокноте мы видели, что σ является встроенной функцией в Flux. Другая функция, которая часто используется в нейронных сетях, называется `ReLU`; в Julia эта функция вызывается `relu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 1\n",
    "\n",
    "Используйте документы, чтобы узнать, что такое ReLU.\n",
    "\n",
    "`relu.([-3, 3])` вернет\n",
    "\n",
    "A) [-3, 3] <br>\n",
    "B) [0, 3] <br>\n",
    "C) [0, 0] <br>\n",
    "D) [3, 3] <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание одного нейрона в Flux\n",
    "\n",
    "Давайте используем `Flux` для построения нашего нейрона с 2 входами и 1 выходом:\n",
    "\n",
    " <img src=\"data/single-neuron.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " \n",
    " Ранее мы поместили два веса в вектор, $ \\mathbf {w} $. Вместо этого Flux помещает веса в матрицу $ 1 \\times 2 $ (то есть матрицу с 1 *строкой* и 2 *столбцами*). \n",
    " \n",
    " Ранее, чтобы вычислить скалярное произведение $ \\mathbf {w} $ и $ \\mathbf {x} $, мы должны были использовать либо функцию `dot`, либо мы должны были транспонировать вектор $ \\mathbf {w} $. :\n",
    " \n",
    "```julia\n",
    "# transpose w\n",
    "b = w' * x\n",
    "# or use dot!\n",
    "b = dot(w, x)\n",
    "```\n",
    "Если вместо этого веса сохраняются в матрице $ 1 \\times 2 $, `W`, то вместо этого мы можем просто умножить` W` и `x`! Мы начинаем со случайных значений наших параметров и данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = rand(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что произведение `W` и` x` теперь будет массивом (вектором) с одним элементом, а не одним числом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это означает, что наше смещение `b` обрабатывается как массив, когда мы используем` Flux`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = rand(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 2\n",
    "\n",
    "Напишите функцию `mypredict`, которая будет принимать один вход, массив` x` и использовать `W`,` b` и встроенный `σ` для генерации выходного прогноза (сохраненного в виде массива). Эта функция определяет нашу нейронную сеть! \n",
    "\n",
    "Подсказка: эта функция будет очень похожа на $ f _ {\\mathbf {w}, \\mathbf {b}} $ из последней записной книжки, но изменилась с тех пор, как изменились наши структуры данных для хранения наших параметров!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 3\n",
    "\n",
    "Определите функцию потерь, называемую `loss`. Она должна принимать два входа: вектор ` x`, в котором хранятся данные  и вектор, в котором хранятся правильные 'метки' для этих данных. `loss` должен возвращать сумму квадратов различий между предсказаниями и правильными метками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет градиентов с помощью Flux: обратное распространение ошибки\n",
    "\n",
    "Для обучения мы знаем, что нам нужен способ вычисления производных функции `loss` по параметрам «W» и «b». До сих пор мы делали это, используя конечные разности. \n",
    "\n",
    "Вместо этого `Flux.jl` реализует числовой метод, называемый **backpropagation**, который вычисляет градиенты (по существу) точно, автоматически, путем косвенного применения правил исчисления. \n",
    "\n",
    "Для этого он предоставляет новый тип объектов, называемый «отслеживаемыми» массивами. Это массивы, которые хранят не только их текущее значение, но также информацию о градиентах, которая используется методом обратного распространения. Если вы хотите понять математику обратного распространения, мы рекомендуем, например, [эту лекция](https://www.youtube.com/watch?v=i94OvYb6noo) [почитать на русском](https://habr.com/ru/post/348028/).\n",
    "\n",
    "Для этого `Flux` предоставляет функцию` param` для определения таких объектов, которые будут содержать информацию о параметрах.\n",
    "\n",
    "Начнем, как обычно, с установки некоторых случайных начальных значений для параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_data = rand(1, 2)  \n",
    "b_data = rand(1)\n",
    "\n",
    "W_data, b_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы настроим объекты `Flux.jl`, которые будут содержать эти значения *и* их производные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = param(W_data)\n",
    "b = param(b_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь `param` - это функция, которую предоставляет Flux для создания объекта, который представляет параметр модели машинного обучения, то есть объект, который имеет как значение, так и информацию о производной.\n",
    "\n",
    "#### Упражнение 4\n",
    "\n",
    "Какой тип у `W`?\n",
    "\n",
    "A) Array (1D) <br>\n",
    "B) Array (2D) <br>\n",
    "C) TrackedArray (1D) <br>\n",
    "D) TrackedArray (2D) <br>\n",
    "E) Parameter (1D) <br>\n",
    "F) Parameter (2D) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 5\n",
    "\n",
    "`W` хранит не только его текущее значение, но также имеет место для хранения информации о градиенте. \n",
    "\n",
    "Вы можете получить доступ к значениям и градиенту весов следующим образом: \n",
    "```julia \n",
    "W.data \n",
    "W.grad \n",
    "``` \n",
    "Что больше на этом этапе?  \n",
    "A) значения весов  \n",
    "B) градиент весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 6\n",
    "\n",
    "Для данных `x` и `y` где\n",
    "\n",
    "```julia\n",
    "x, y = [0.413759, 0.692204], [0.845677]\n",
    "```\n",
    "примените функцию потерь к `x` и` y`, чтобы получить новую переменную `l`. Какой тип `l`? (Сколько у нее измерений?)\n",
    "\n",
    "A) Array (0D) <br>\n",
    "B) Array (1D) <br>\n",
    "C) TrackedArray (0D) <br>\n",
    "D) TrackedArray (1D)<br> \n",
    "E) Float64<br>\n",
    "F) Int64<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стохастический градиентный спуск\n",
    "\n",
    "Теперь мы можем использовать эти функции для переопределения стохастического градиентного спуска, следуя методу, который мы использовали в предыдущем блокноте, но теперь используя обратное распространение!\n",
    "\n",
    "#### Упражнение 7\n",
    "\n",
    "Измените код из предыдущей записной книжки для стохастического градиентного спуска, чтобы вместо него использовать Flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование стохастического градиентного спуска\n",
    "\n",
    "Давайте посмотрим на значения, хранящиеся в `b`, перед тем как запустить стохастический градиентный спуск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После запуска `stochastic_gradient_descent` мы находим следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_final, b_final = stochastic_gradient_descent(loss, W, b, xs, ys, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы можем взглянуть на значения `W_final` и` b_final`, которые наша машина научила генерировать желаемую классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 8\n",
    "\n",
    "Отобразите на графике данные и обученную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 9\n",
    "\n",
    "Отображайте промежуточные этабы обучения, чтоб получить анимацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Автоматизация с Flux.jl\n",
    "\n",
    "Нам нужно будет повторить вышеописанный процесс для множества различных систем. К счастью, `Flux.jl` предоставляет нам инструменты для автоматизации этого!\n",
    "\n",
    "Flux позволяет создать нейрон простым способом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dense(2, 1, σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2` и` 1` относятся к числу входов и выходов, а нейрон определяется с помощью функции $ \\sigma $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы создали объект типа «Dense», определенный как «Flux», с именем «model». Это так называемый «плотный слой нейронной сети» (или полносвязный перцептрон). Параметры, которые будут изменены в процессе обучения, живут *внутри* объекта `модель`.\n",
    "\n",
    "#### Упражнение 10\n",
    "\n",
    "Выясните, какие переменные живут внутри объекта `model` и какого они типа. Как это соотносится с вызовом для создания «плотного» объекта, с которого мы начали?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модельный объект как функция\n",
    "\n",
    "Мы можем применить объект `model` к данным, как если бы это была стандартная функция:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 11\n",
    "\n",
    "Докажите себе, что вы понимаете, что происходит, когда мы называем модель. Создайте два массива `W` и` b` с теми же элементами, что и у `model.W` и` model.b`. Используйте `W` и` b` для генерации того же ответа, который вы получаете, когда мы называем `model ([. 5, .5])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование Flux\n",
    "\n",
    "Теперь нам нужно предоставить Flux три элемента информации: \n",
    "1. Функция потерь \n",
    "2. Некоторые обучающие данные \n",
    "3. Метод оптимизации\n",
    "\n",
    "### Функции потери\n",
    "\n",
    "В Flux встроены различные функции потерь, например, среднеквадратическая ошибка (`mse`), которую мы уже использовали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.mse(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще часто используется перекрестная энтропия, `Flux.crossentropy`.\n",
    "\n",
    "### Данные\n",
    "\n",
    "Данные могут принимать несколько различных форм. Одна из них - это **итератор**, состоящий из пар $ (x, y) $ данных и меток. Мы можем добиться этого с помощью zip.\n",
    "\n",
    "#### Упражнение 12\n",
    "\n",
    "Используйте `zip`, чтобы' сжать '` xs` и `ys`. Затем используйте функцию `collect`, чтобы проверить, что на самом деле делает` zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы оптимизации\n",
    "\n",
    "Теперь нам нужно сообщить Flux, какую процедуру оптимизации использовать. Он имеет несколько встроенных; используемый нами алгоритм стохастического градиентного спуска называется SGD. Мы должны передать ему две вещи: список объектов параметров, которые будут изменены подпрограммой оптимизации, и размер шага:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD([model.W, model.b], 0.01)\n",
    "# дать список параметров, которые будут изменены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисления градиента и обновления параметров будут выполняться этой функцией оптимизатора; мы не видим этих подробностей, но если вам интересно, вы можете, конечно, взглянуть на исходный код `Flux.jl`!\n",
    "\n",
    "### Обучение\n",
    "\n",
    "Теперь у нас есть все, чтобы на самом деле **обучить** нашу модель (один нейрон) на данных. «Обучение» относится к использованию предварительно помеченных данных для изучения функции, которая связывает входные данные с желаемыми выходными данными, указанными метками. \n",
    "\n",
    "`Flux` предоставляет функцию` train! `, которая выполняет один проход через данные и выполняет один шаг оптимизации, используя функцию частичной стоимости для каждой точки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы можем просто повторить это несколько раз, чтобы обучить сеть еще больше и настроить ее к минимуму функции стоимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:100\n",
    "    Flux.train!(loss, data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим на параметры после тренировки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо того, чтобы записывать список параметров для изменения, `Flux` предоставляет функцию` params`, которая извлекает все доступные параметры из модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(params(model), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление дополнительных функций\n",
    "\n",
    "#### Упражнение 13\n",
    "\n",
    "До сих пор мы только что использовали два признака, красный и зеленый цвета. \n",
    "\n",
    "1. Добавьте третью функцию, синюю. Подготовьте новые данные. \n",
    "1. Обучить нейрон с 3 входами и 1 выходом по данным. \n",
    "1. Можете ли вы найти хороший способ визуализировать результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
