{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в нейроны\n",
    "\n",
    "На данный момент мы знаем, как создавать модели и заставлять компьютер автоматически учиться сопоставлять модель с данными. Это ядро того, как работает любой метод машинного обучения. \n",
    "\n",
    "Теперь давайте сузим наше внимание и посмотрим на **нейронные сети**. Нейронные сети (или «нейросети», для краткости) - это особый выбор **модели**. Это сеть, состоящая из **нейронов**; что, в свою очередь, приводит к вопросу 'что такое нейрон?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модели с несколькими входами\n",
    "\n",
    "До сих пор мы использовали сигмовидную функцию в качестве нашей модели. Одна из форм сигмоидальной функции, которую мы использовали,\n",
    "\n",
    "$$\\sigma_{w, b}(x) = \\frac{1}{1 + \\exp(-wx + b)},$$\n",
    "\n",
    "где `x` и` w` одинарные числа. Мы использовали эту функцию, чтобы смоделировать, как количество зеленого цвета на изображении (`x`) может быть использовано для определения того, что изображено на изображении. Но что, если бы у нас было больше данных, которые мы хотели бы разметить? Мы можем расширить нашу модель, включив в нее несколько параметров, таких как\n",
    "\n",
    "$$\\sigma_{\\mathbf{w},b}(\\mathbf{x}) = \\frac{1}{1 + \\exp(-w_1 x_1 - w_2 x_2 - \\cdots - w_n x_n + b)}$$\n",
    "\n",
    "Обратите внимание, что теперь $ \\mathbf {x} $ и $ \\mathbf {w} $ являются векторами со многими компонентами, а не одним числом. \n",
    "\n",
    "Например, $ x_1 $ может быть количеством зеленого цвета на изображении, $ x_2 $ может быть высотой объекта на картинке, $ x_3 $ может быть шириной и т. д. Наша модель теперь имеет больше параметров, но та же самая идея градиентного спуска («катание шара вниз») все равно будет работать для обучения. \n",
    "\n",
    "Эта версия сигмоидальной модели, которая принимает несколько входов, является примером **нейрона (перцептрона)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле это карикатура на настоящие, биологические нейроны. И *искусственные*, и *биологические* нейроны имеют несколько входов $ x_1, \\ldots, x_n $ и один выход $ y $. Схематично они выглядят так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"draw_neural_net.jl\") # там рисовалка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly() # plotlyjs() # pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_inputs, number_neurons = 4, 1\n",
    "\n",
    "draw_network([number_inputs, number_neurons])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы должны это воспринимать, как течение информации слева направо:\n",
    "- Поступает 4 фрагмента входной информации (показано зеленым цветом слева);\n",
    "\n",
    "- нейрон (показанный красным справа) получает все входные данные, обрабатывает их и выводит одно число справа.\n",
    "\n",
    "Другими словами, нейрон - это просто тип функции, которая принимает несколько входов и возвращает один выход. \n",
    "\n",
    "Самый простой интересный случай, который мы рассмотрим в этой записной книжке, это когда есть только две части входных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_network([2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая связь между кружками выше представляет **вес** $ w $, который можно изменить, чтобы позволить нейрону учиться, поэтому в этом случае нейрон имеет два веса: $ w_1 $ и $ w_2 $. \n",
    "\n",
    "Нейрон также имеет одиночное смещение $ b $ и **функцию активации**, которую мы возьмем за сигмоидальную функцию $ \\sigma $, которую мы уже использовали. (Обратите внимание, что могут использоваться другие функции активации!)\n",
    "\n",
    "Давайте назовем наш нейрон $ f_ {w_1, w_2, b} (x_1, x_2) $, где \n",
    "\n",
    "$$ f_ {w_1, w_2, b} (x_1, x_2 ): = \\sigma (w_1 x_1 + w_2 x_2 + b). $$ \n",
    "\n",
    "Обратите внимание, что $ f_ {w_1, w_2, b} (x_1, x_2) $ имеет 3 параметра: два веса и смещение. \n",
    "\n",
    "Чтобы упростить запись и подготовиться к более сложным сценариям позже, мы поместим два веса в вектор, а два значения данных в другой вектор:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix};\n",
    "\\qquad\n",
    "\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Таким образом, мы имеем\n",
    "\n",
    "$$f_{\\mathbf{w}, b}(\\mathbf{x}) = \\sigma(\\mathbf{w} \\cdot \\mathbf{x} + b),$$\n",
    "\n",
    "где скалярное произведение $ \\mathbf {w} \\cdot \\mathbf {x} $ является сокращенным синтаксисом для $ w_1 x_1 + w_2 x_2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упражнение 1\n",
    "\n",
    "Объявите функцию `f (x, w, b)` в Julia. `f` должен принимать ` x` и `w` как векторы, а` b` - как скаляр. Кроме того `F` должен вызывать\n",
    "\n",
    "```julia\n",
    "σ(x) = 1 / (1 + exp(-x))\n",
    "```\n",
    "\n",
    "Какой выход вы получаете для\n",
    "\n",
    "```julia\n",
    "f(3, 4, 5)\n",
    "```\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
