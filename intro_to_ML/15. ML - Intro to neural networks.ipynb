{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронные сети\n",
    "\n",
    "Теперь, когда мы знаем, что такое нейроны, мы готовы к последнему шагу: нейронной сети!\n",
    "\n",
    "Нейронная сеть буквально состоит из нейронов, которые связаны друг с другом. Пока мы только что посмотрели на отдельные нейроны, которые имеют только один выход. Что если мы хотим получить несколько выходов?\n",
    "\n",
    "\n",
    "### Модели с несколькими выходами\n",
    "\n",
    "Что если бы мы хотели провести различие между яблоками, бананами и виноградом? Мы могли бы использовать *векторы* значений `0` или` 1`, чтобы символизировать каждый вывод.\n",
    "\n",
    "<img src=\"data/fruit-salad.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Идея использования векторов состоит в том, что различные направления в пространстве выходов кодируют информацию о различных типах входов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы расширяем нашу предыдущую модель, чтобы получить несколько выходов, повторяя ее с разными весами. Для первого элемента массива мы будем использовать:\n",
    "\n",
    "$$\\sigma(x;w^{(1)},b^{(1)}) := \\frac{1}{1 + \\exp(-w^{(1)} \\cdot x + b^{(1)})};$$\n",
    "\n",
    "тогда для второго мы будем использовать\n",
    "\n",
    "$$\\sigma(x;w^{(2)},b^{(2)}) := \\frac{1}{1 + \\exp(-w^{(2)} \\cdot x + b^{(2)})};$$\n",
    "\n",
    "и если бы вы хотели $ n $ выходов, вы бы имели для каждого\n",
    "\n",
    "$$\\sigma(x;w^{(i)},b^{(i)}) := \\frac{1}{1 + \\exp(-w^{(i)} \\cdot x + b^{(i)})}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что все эти уравнения одинаковы, за исключением параметров, поэтому мы можем написать эту модель более кратко, как изложено ниже. Давайте напишем $ b $ как массив:\n",
    "\n",
    "$$b=\\left[\\begin{array}{c}\n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n}\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "и представим наш массив весов в качестве матрицы:\n",
    "\n",
    "$$ \\mathsf{W}=\\left[\\begin{array}{c}\n",
    "\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\end{array}\\begin{array}{cccc}\n",
    "w_{1}^{(1)} & w_{2}^{(1)} & \\ldots & w_{n}^{(1)}\\\\\n",
    "w_{1}^{(2)} & w_{2}^{(2)} & \\ldots & w_{n}^{(2)}\\\\\n",
    "\\vdots & \\vdots &  & \\vdots\\\\\n",
    "w_{1}^{(n)} & w_{2}^{(n)} & \\ldots & w_{n}^{(n)}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Мы можем записать все это в одну строку как:\n",
    "\n",
    "$$\\sigma(x;w,b)= \\left[\\begin{array}{c}\n",
    "\\sigma^{(1)}\\\\\n",
    "\\sigma^{(2)}\\\\\n",
    "\\vdots\\\\\n",
    "\\sigma^{(n)}\n",
    "\\end{array}\\right] = \\frac{1}{1 + \\exp(-\\mathsf{W} x + b)}$$\n",
    "\n",
    "$W x$ это операция под названием «матричное умножение»\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "W_{11} & W_{12} & W_{13}\\\\ \n",
    " W_{21}& W_{22} & W_{23}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1\\\\ \n",
    "x_2\\\\\n",
    "x_3\n",
    "\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "W_{11}x_1 + W_{12}x_2 + W_{13}x_3\\\\ \n",
    " W_{21}x_1 + W_{22}x_2 + W_{23}x_3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Он берет каждый столбец весов и делает скалярное произведение против $ x $ (помните, именно так был определен $ \\sigma ^ {(i)} $) и выделяет вектор, выполняя это с каждым столбцом. В результате получается вектор, который заставляет эту версию функции давать вектор выходных данных, который мы можем использовать для кодирования большего набора вариантов.\n",
    "\n",
    "Матричное умножение также интересно, поскольку **графические процессоры (на видео картах) в основном являются просто машинами умножения матриц**, что означает, что, если написать уравнение таким образом, результат можно вычислить очень быстро."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта версия сигмоидальной функции «множественный вход и множественный выход» известна как *слой нейронов*. \n",
    "\n",
    "Ранее мы работали с одним нейроном, который мы визуализировали как\n",
    "\n",
    "<img src=\"data/single-neuron.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "где у нас есть два куска данных (зеленый), поступающих в один нейрон (розовый), который возвратил один вывод. Мы могли бы использовать этот единственный выход для бинарной классификации - чтобы идентифицировать изображение фрукта как `1`, что означает банан или как` 0`, что означает не банан (или яблоко).\n",
    "\n",
    "Для выполнения недвоичной классификации мы можем использовать слой нейронов, который мы можем визуализировать как\n",
    "\n",
    "<img src=\"data/single-layer.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Теперь мы поместили несколько нейронов друг на друга, чтобы они работали вместе и обучались выводить результаты более сложных функций. \n",
    "\n",
    "У нас все еще есть два входных фрагмента данных, но теперь есть несколько нейронов, каждый из которых производит вывод для данной двоичной классификации: \n",
    "* neuron 1: \"это яблоко?\"\n",
    "* neuron 2: \"это банан?\"\n",
    "* neuron 3: \"это виноград?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
